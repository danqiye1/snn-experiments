{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catastrophic Forgetting\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The phenomenon of catastrophic forgetting, or catastrophic interference, was first observed by McCloskey and Cohen (1989). It is especially salient in online learning, where training data is fed sequentially to a machine learning model for training. In this notebook, we will explore the effects of catastrophic interference in the PES learning rule on MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nengo\n",
    "import nengo_dl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from nengo_extras.gui import image_display_function\n",
    "from nengo_extras.vision import Gabor, Mask\n",
    "from nengo_extras.data import one_hot_from_labels\n",
    "from nengo.utils.filter_design import cont2discrete\n",
    "from nengo_gui.ipython import IPythonViz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Digit Recognition\n",
    "\n",
    "We will experiment on catastrophic interference with MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "n_train, height, width = X_train.shape\n",
    "n_test = len(y_test)\n",
    "n_classes = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIwAAACMCAAAAACLqx7iAAAOHUlEQVR4nO2bWVMby5LHM2vr6r3VQiz2te+ZiPn+n2giZmKujwGBet9rmwfh7RiOJQS+88CfFyJoVf+UlZWVVZkAvOlNb3rTm970pje96U1vetP/O+HLDkcYYxQRHCIlCHqZlUXOBWeUUgIA4Kw2Smultfnp0+xlYUBEgccAAKnHmZ2qsl1YkKRh4EuPAwCaZRqGoe+74dVhaLBahQLBoRcE3NbXbjY8Or9cZ2kcSkBAPTRVURU7t8yvA4MAbv9bkJ6dZx5xjsg4FmaHQ2tldvHH1WadJwEg4NLstjdbZob253FOgkFEwhglCODAGoNetrm8XEniHPGT2NOyLyoM8ov3Hy426zQEAJhKiWruJCenwODD+wmhhBBCCAIiYZ4n2AOMBS85vzpPJXGOyCgSylXFEIbv3r9/v1mvOAAASCkognPukVccaxmkXHDBBeeMICLzwjDw9jDWIg+z9SriBBwK32fKtD324fs/Pl6t0oc32WUc+n6YtT3JMgTAIeXS30tQRMLDZBUHCODAWYdUBFHgMQQAyhlZ1GYWc3D18d0mpPtRdFuVRVHU/XwCDGGUIjhkXhBFURhFoeSIRMT5ehURAAsOHBDCOKOICA7AWSeTc6GDzcUq2nvIMg/19u7uvqi7+eeVfSgM8zyPE3DIZBjHcRzHkc8RiZfkmzwiAD/4ACJYoxatLfWt9SPJAMCqZVmmrr672xVVO6pnWQYRCZVxHPsMHFIZRGEURVEoGSIRcZYnD+//0ZI4T/3Qd5N2eurYDEYv87JMfXO33VXNc30GCeUyPTs/Szx0QIT0ZeD7vhQMEHkQycc/poeqrPtx0cCnsRJWq3le1Dx05d12Vw/Tc2G4jM8+fPxw5iM4ZJx/XU2AVHj08Y9Nzfa26CZrkQpfUKOXeVZaTWNbFlW7KP3I2j4Ehokwu/yP/7yKCDgghCChhBBEQEDyBIub6u2nbasAkBBGUatlVspoNY9t24/G2mfBACLlQbp59yGh4Ny30P9FP9mbAICZu+LmutOEIACC02pZlLbGqHkcp+XxNx0A45x1yLwgpg9++te0wznrnHPOARBCyf7Peqx3t4OhFJ0D67RSSmtnrVbLrJ54069hnNXLsmiHj2wme6FzxhhrnEMmHljATM3ubrKUoHPOOqO1McY5Z4zWTw10CIwi4zhO8+w/+YxVi9baOCIcfRhRT115rxxBdA6cs9ZY65wD+6i3HA7jYBqHvuvEj87qAB6mzKppnNViLJGW7Ldjo8auLu3+AQfgnHPw5ecEGAduHvu2qanPkPwUbQHsMrTtOC/aUn/RJvAQYJ6noe9+OfixMABg1dRVu9BEgjI0xgDhgjO3/8pg9VDtdu2ktKV+kmVhIDjrx2n+OZV7CRjQU3P3GYck8Bgs8+K8KKX7CXDgzNTe/+tzMWpjiYzTNE7iOJj7+bHd52Vg6q1U7SoJhBn6AcMz6gMAoHPOqrG++Z//vhmMc+gFcZLkm01mu8k87RwnwZip3tK57bLY023VYWbDdL+2nDFTX93+73996p0D5DKI0s37caTV8FQ0ORXGLn1JlnEee0/VZYuDWOUxAQCweu7r4u7mz089AAATMkw6A0pU7WPp00vAgJ5a1IuaWqHqqiMqyFdScErBTG253d4Vdb9/Tk/zApwuotv1R5vmQBgzE6emqQu5apuR6CCLaRT6BMxQXH/+tK3HL0/aCRl3LR939WvBWD3ZeRwbyVQ/KLRBGtEcOAfd3//5rz/vu29JpF06nAuquvqJ7fBkGKetJuPgcaKmxSKJV4lAGUq0Y7W9uaun71aOmUzP0KrltSzjjFFAJkZRzwbQq6syDift0JllHMb5u2XsjDk62h0HAwAAdlkIGgBw8zzPszIWkDLheYI9uaO/Ggx8TaS+HgiRB0neTn37IjTPO2tTSsg+ceHRulN6qJ7IPn8HDEF0zhptgYf5bFWzFf8+GLBqHsdxmhl68ay6bSzJ0fH2pWDM1BbSC8OAcerH8yqNA6nMyTjPg9FDSQx4QSiQeaHKsiQKhtNN8zwY1cE0WhHFklIe2DTL0tiaR47yvwNGD6obMMwyn3MuwiRbrVbGmCfT/leFMWaGxcvOcp9zwbwwWa0bi3SY/h0wAABDs7uNGTARkSDbXCkRNN1onbXW6Gfa6Pkwbiw/M6OZlCLMr0aWlHXbK6OVmsbxd8OAqq/NbGSSCpZemuCsrNp2XpZ5aBszH53/ngijWzvNmJydxRiuIVrXVdMO0zS2Epfx+AT4RBijZuufv7uMIwycjJOkaYdxHBrhlql+jmlOgLFgDCvubs7Eyic+930ZROM0jq2HRqMyxtpHb3tfBQYA9NjcfYpsn8d+GEgviOd5nvqQo2PjOC/HHuNOrB2o/v5fbOpmJ3zg3AuV0mqKODpeNz26py8cXgPGjCWHaQYRBAQklc5YoyVayyQjzrrHrhFfD2ZuCGjwwtCLKDBKAMCimhdghCCSRR+zl59a4lEjQcd8yXTqC84IAJB0HBciGOdcDNOjF76vBGMWREeoncp1msahTwFApLOTgQx8KSu0RwTjU2GcRjDODOXN+fnFuXYBBYAwZ2EYBFJ61Onl91kGrLJKT81ue1FPxlobUQAWiziQnhAM1KLcwbY52TLOalBj1zSDQQpaqUASECJkBAHBLNqSWdvDrPMiNUqllDLIOVF9m0ah50lKon2t2FFRtcP0G2EAFCDjqJrVKkvSJEkTZH5iKRNeGN/d7dRh++ZLlZLN0qLq7tM0W63X58AD4AEKL4jSLKJLd1gK+FIwTo9mqO+jJMs3nZOhj9Tn0g/jJOJLvTtskJeDMcvQeUFUt6ML8tlSSoX0pC+5Kq+fqEm9Fsx+XU3TNM+K571yAADEp5TYNs/iUP/dNf3LwwAAuEkt8+RddF8cljtn6jzP23FW8Mtz1Us3ZphuGZLywTIAyHyTrvK8Iejcb4cBWJZmWL7eZBHmB1GcJItWvw7EL3Pl9Bd9yTYtAFLGuRCCkb/Wdx/RC1kGkRBKKUFEwDyW34Z11millD4kH34hGEc596QnGKOUfnyXib0ZHFgzjX3XNuPyWLn2dWCQeX4Uxb70hPAuP+ZyD2OdmfumLouqPyTJeiEYzw/iNM/iMJC+v75YP8A4o6aubaqqWuwBO/eLwAgvCKN0tc7TKPSDMMnih2myVi/j0Pd9f9C2fRoMEkoZYzKIojjL8lUSBtIPwtBnCLC/h7RaK3XgAepEy1DPDwI/ipIkSdI0jnxPeJ709i00ABwo/m2J9CVhCA/SLEvTLEuTKAp9KThljPOvN+a4L9v+Dhgqg2S9OV/n+SqNQ+kJxgh+V/UH0GpRyrgDWxNPgGHcC+L8/PJys85XaeQLRgl5iL7OIQKoaezqunu0cefFYJAQRul+OW8uLtZ5lkaB3N/YIwKAM8Zqraaha8v7m6I/8HzwLBhHhC9lFKfZarVe51kShf4PfTTo1DR0fds0dVXc3zQH1nyeZxnuJ3Gyys/WqyxN4tD3vB97AJ2emvK+KMqqrKuurg6syT0HhoggyfP87PxikyehlIJTiu47L3XT0Ba31zfbXVE0rVqWA2GObsEllHp+kp2dnZ1fXG5WkeSMfuuPQASwyzR01d31p8+390XZDoePfQwMIiIV0g/jNDtb55uz8zz1xdf5cc5YY7RexqFry93t9c1dUdfHlAiPmiYkzAuzVb7KsixLsyyLpfft26Cz8zz0Q981TVNX5X1Rtf1R5cpjYCilXri6vHp3tkriMAz9QP7wcavGtirKqiqruhn6vh+m425gD4chnDPuJ5v3f/zzIot9z+OMEfzObe3cN+X29vau2JV1v2il9ZGFlgNhKGNCCC6C7PLdh4+XaSgY27uthS9uO/ZtdX/z+Xq725XNs6pPv4ahQuz7BD2Pe0F2/o/LTR77e7dFBGetsUZpNfZdU+1ub7b3ZfmtG+GFYViYJmHgCc/zPOnHq4vLLPS+hTh0epmHoR+6tmmqqiiK+ki3PQaGp1cXeSyl50kpZRAmSfRDuDXL0FZlUddV0zRt3/XjdMTN2XEwJMzffbzMfOl5vpSex4Vg1LmvAUpNfVtst7f3ZVm33bQs2miDzyqq/BKGx+vzqw/vVoEUnpRSPLitA7d323nsmur+5vr6riibbliOvBP/JQwiEkIZY5QQIuLLj++vLjLf40J632UJAE5rvfRtXRa72+3trqq74cQi5WMwhDLh+UEgBWcyOnv3/mode5xx8ePegXrou7q42+2Ksijrrn9m/e3vYagQfpyusiiUnozSfJ3HPqeE/WUfc3NTFne319td3ffDOC2vUUpGJoJotbnY5HHo+0EYhoHHCf50cJ/b8vb25s9PN0W3aH1UkeBwGMK8IFltrq7O0ijwpRScU/Jdlo/ggICZ6vvb6+vrT59uyvEF+iCegKEiSPPNxdW7TRL6UogvwdYYo411SMAao+e+vtve3m63u6p/GZTHYfxkfXH1/h/vNqH/XYYAVo3TrCwhYKaxa5umLMqiLNoTK+t/D8Nksj6/vLq8OPuhKcYsQ9v2kyEMVFvd78q264Z+6F9qjh6HISKI0zRN4h9ZhqGtymbQlOJSbj/fFN28aKW1OiXM/RIGCaGUgFV2X1dDAKvmaeiboqh6TRnOxfWnz7tB22eG/SNgrJq62uNuKNE5MAgAVs3zOLRVVQ+aMpyr2+2ugp/67F8BRg8lU03xOQ6+JE/OaaXmaWy7bjaEgm7L+oik/xQY1cFcBqEvBYADC+jAWWOUXqZ5VpYgmql/5N/rTtcjRxXKuGCMMUq/zoMD66wzxhjnAMEZrY4rEr/pTW9605ve9KaT9X/4XuKn4jzhvAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=140x140>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n",
      "Max Pixel Val: 255\n",
      "Min Pixel Val: 0\n"
     ]
    }
   ],
   "source": [
    "Image.fromarray(X_train[0]) \\\n",
    "    .resize((height * 5, width * 5)) \\\n",
    "    .show()\n",
    "\n",
    "print(f\"Label: {y_train[0]}\")\n",
    "print(f\"Max Pixel Val: {np.max(X_train[0])}\")\n",
    "print(f\"Min Pixel Val: {np.min(X_train[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch preprocess the data into unit vector.\n",
    "def preprocess(X):\n",
    "    X = X.reshape(len(X), -1)\n",
    "    X = X - X.mean(axis=1, keepdims=True)\n",
    "    return X / np.linalg.norm(X, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and One hot encode\n",
    "X_train = preprocess(X_train)\n",
    "y_train = one_hot_from_labels(y_train)\n",
    "X_test = preprocess(X_test)\n",
    "y_test = one_hot_from_labels(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "\n",
    "We build a 2 ensemble neural network with Nengo, and set the learning with PES learning rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some network configuration hyperparameters\n",
    "input_display_time = 1\n",
    "n_neurons = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks in Nengo are fixed-encoding networks, whereby the encoders are fixed to a certain randomly generated value. Previous research has shown that Gabor filters best extracts the features of an image. Unlike in deep learning, where these Gabor filters are derived from backpropagation, we can only generate these Gabor filters randomly because backpropagation cannot be used in fixed-encoding SNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the encoders for the neural ensemble\n",
    "gabor_size = (11, 11)\n",
    "# Set the rng state (using a fixed seed that works)\n",
    "rng = np.random.RandomState(9)\n",
    "encoders = Gabor().generate(n_neurons, gabor_size, rng=rng)\n",
    "encoders = Mask((height, width)).populate(encoders, rng=rng, flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbe75b09bd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(encoders[1].reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the nengo model rendered as an interactive demo in Nengo GUI. You can see the effects of catastrophic forgetting when you inhibit the learning by moving the slider of inhibitor to 1 (Wait for 30s for the simulation to run and learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <script type=\"text/javascript\" id=\"9e02dd47-f071-4c77-bf31-5fb626b6e890\">\n",
       "            {\n",
       "                let req = new XMLHttpRequest();\n",
       "                req.addEventListener(\"load\", function() {\n",
       "                    if (this.status != 200 && this.response != 'OK') {\n",
       "                        let p = document.getElementById('9e02dd47-f071-4c77-bf31-5fb626b6e890').parentNode;\n",
       "                        p.innerHTML +=\n",
       "                            'The nengo_gui.jupyter notebook server ' +\n",
       "                            'extension was not loaded. Please activate it ' +\n",
       "                            'with the following command:' +\n",
       "                            '<pre>jupyter serverextension enable ' +\n",
       "                            'nengo_gui.jupyter</pre>';\n",
       "                        p.classList.add('output_stderr');\n",
       "                    }\n",
       "                });\n",
       "                req.open('GET', './nengo/check', true);\n",
       "                req.send();\n",
       "            }\n",
       "            </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vdom.v1+json": {
       "attributes": {
        "id": "96e6e448-4c1d-49bf-9d6b-9e970a7e7cb7"
       },
       "children": [
        {
         "attributes": {
          "allowfullscreen": "allowfullscreen",
          "class": "cell",
          "frameborder": "0",
          "height": "600",
          "src": "./nengo/35945/?token=99836fb75c8e74b36e1f6617d57d00840eb19125d49d456e",
          "style": {
           "border": "1px solid #eee",
           "boxSizing": "border-box"
          },
          "width": "100%"
         },
         "tagName": "iframe"
        }
       ],
       "tagName": "div"
      },
      "text/html": [
       "\n",
       "                <div id=\"df6b55f6-4fa8-4979-821f-bf131759ad4d\">\n",
       "                    <iframe\n",
       "                        src=\"./nengo/35945/?token=99836fb75c8e74b36e1f6617d57d00840eb19125d49d456e\"\n",
       "                        width=\"100%\"\n",
       "                        height=\"600\"\n",
       "                        frameborder=\"0\"\n",
       "                        class=\"cell\"\n",
       "                        style=\"border: 1px solid #eee; box-sizing: border-box;\"\n",
       "                        allowfullscreen></iframe>\n",
       "                </div>\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with nengo.Network(seed=3) as model:\n",
    "\n",
    "    input_node = nengo.Node(\n",
    "        nengo.processes.PresentInput(X_train, input_display_time),\n",
    "        label=\"Input\"\n",
    "    )\n",
    "\n",
    "    # Pre-synaptic ensemble\n",
    "    pre_ens = nengo.Ensemble(\n",
    "        n_neurons=n_neurons,\n",
    "        dimensions=height * width,\n",
    "        radius=1\n",
    "    )\n",
    "    \n",
    "    nengo.Connection(input_node, pre_ens)\n",
    "    \n",
    "    post_ens = nengo.Ensemble(\n",
    "        n_neurons=30*n_classes,\n",
    "        dimensions=n_classes,\n",
    "        radius=5\n",
    "    )\n",
    "    \n",
    "    # Connection with synapse weight to be learned by PES\n",
    "    # Weights are randomly initialized\n",
    "    conn = nengo.Connection(\n",
    "        pre_ens, post_ens,\n",
    "        learning_rule_type=nengo.PES(),\n",
    "        transform=np.random.rand(n_classes, width*height)\n",
    "    )\n",
    "    \n",
    "    # Error signal representation\n",
    "    error = nengo.Ensemble(\n",
    "        n_neurons=30 * n_classes,\n",
    "        dimensions=n_classes,\n",
    "        radius=5\n",
    "    )\n",
    "    \n",
    "    gt_node = nengo.Node(\n",
    "        nengo.processes.PresentInput(y_train, input_display_time),\n",
    "        label=\"Ground Truth\"\n",
    "    )\n",
    "    nengo.Connection(post_ens, error)\n",
    "    nengo.Connection(gt_node, error, transform=-1)\n",
    "    nengo.Connection(error, conn.learning_rule)\n",
    "    \n",
    "    # Input image display (for nengo_gui)\n",
    "    image_shape = (1, 28, 28)\n",
    "    display_func = image_display_function(image_shape, offset=1, scale=128)\n",
    "    display_node = nengo.Node(display_func, size_in=input_node.size_out)\n",
    "    nengo.Connection(input_node, display_node, synapse=None)\n",
    "    \n",
    "    # Error inhibition control\n",
    "    inhibitor = nengo.Node([0])\n",
    "    nengo.Connection(\n",
    "        inhibitor, error.neurons, \n",
    "        transform=-100*np.ones((error.n_neurons, 1))\n",
    "    )\n",
    "    \n",
    "\n",
    "# Network visualization\n",
    "IPythonViz(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that once inhibitor is turned on, the neural network stops learning and just predicts everything as the predicted label of the last seen sample. This means that the last seen sample before inhibition has turned on has caused catastrophic forgetting in the synapse weights between pre-synaptic and post-synaptic neuron ensemble. This needs to be mitigated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Offline Learning\n",
    "\n",
    "Of course, the phenomenon of catastrophic forgetting is also visible in offline learning. In the next experiment, we use a LeNet5 built with PyTorch to simulate this behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.convnet = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc2 = nn.Linear(in_features=84, out_features=10)\n",
    "        \n",
    "    def forward(self, img):\n",
    "        X = self.convnet(img)\n",
    "        X = torch.flatten(X, start_dim=1)\n",
    "        X = self.fc1(X)\n",
    "        X = nn.functional.relu(X)\n",
    "        X = self.fc2(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network will still train on a one hot vector of 10 classes (0 - 9), but we are going to not let it see the number 9 ever during initial training. Thus in PyTorch, we will have to create our custom dataset from MNIST with the filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IncompleteMNIST(Dataset):\n",
    "    \"\"\" Class for incomplete MNIST \"\"\"\n",
    "    \n",
    "    def __init__(self, holdout=True, exclude=9, train=True):\n",
    "        \"\"\"\n",
    "        :param holdout: mode of instantiation of this dataset. If holdout=True,\n",
    "            data of a certain label will be excluded from training. If holdout=False,\n",
    "            only the excluded data will be trained.\n",
    "        :param exclude: label of data to be excluded during holdout.\n",
    "        :param train: Set training or testing mode.\n",
    "        \"\"\"\n",
    "        if train:\n",
    "            (imgs, labels), _ = tf.keras.datasets.mnist.load_data()\n",
    "        else:\n",
    "            _, (imgs, labels) = tf.keras.datasets.mnist.load_data()\n",
    "            \n",
    "        if holdout:\n",
    "            self.imgs = imgs[labels != exclude]\n",
    "            self.labels = labels[labels != exclude]\n",
    "        else:\n",
    "            self.imgs = imgs[labels == exclude]\n",
    "            self.labels = labels[labels == exclude]\n",
    "        \n",
    "        # Padding because LeNet5 requires 32 x 32 x 1 images as inputs\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Pad(2)\n",
    "        ])\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.imgs[idx]), self.labels[idx]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: torch.Size([1, 32, 32])\n",
      "label: 5\n",
      "54051 training data\n",
      "8991 validation data\n"
     ]
    }
   ],
   "source": [
    "trainset = IncompleteMNIST()\n",
    "valset = IncompleteMNIST(train=False)\n",
    "img, label = trainset[0]\n",
    "print(f\"Image size: {img.shape}\")\n",
    "print(f\"label: {label}\")\n",
    "print(f\"{len(trainset)} training data\")\n",
    "print(f\"{len(valset)} validation data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we shall perform training on the data that was held out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training\n",
    "model = LeNet()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                    trainset, \n",
    "                    batch_size=4, \n",
    "                    shuffle=True,\n",
    "                    num_workers=2\n",
    "                )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "                    valset, \n",
    "                    batch_size=4, \n",
    "                    shuffle=True,\n",
    "                    num_workers=2\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    running_loss = 0.0\n",
    "    last_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        imgs, labels = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(imgs)\n",
    "        \n",
    "        # Compute loss and backpropagate error gradients\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient descent\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Gather running loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Calculate avg loss across 1000 batches\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000\n",
    "            running_loss = 0.0\n",
    "        \n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfff90fc35724270ac89ab43f70c720b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Inner training loop\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Turn off training for reporting\u001b[39;00m\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Compute loss and backpropagate error gradients\u001b[39;00m\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Gradient descent\u001b[39;00m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Epoch Training\n",
    "num_epochs = 40\n",
    "\n",
    "best_vloss = 1_000_000\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train(True)\n",
    "    \n",
    "    # Inner training loop\n",
    "    avg_loss = train(model)\n",
    "    \n",
    "    # Turn off training for reporting\n",
    "    model.train(False)\n",
    "    \n",
    "    running_vloss = 0.0\n",
    "    for i, vdata in enumerate(val_loader):\n",
    "        v_inputs, v_labels = vdata\n",
    "        v_outputs = model(v_inputs)\n",
    "        v_loss = criterion(v_outputs, v_labels)\n",
    "        running_vloss += v_loss\n",
    "        \n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    tqdm.write(f\"Train loss: {avg_loss}, Validation loss: {avg_vloss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "We have seen the effects of catastrophic forgetting on neural networks in both a sequential learning scenario and a offline batch learning scenario. After seeing that such a phenomenon happens, we can move to try and resolve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legendre Memory Units\n",
    "\n",
    "LMUs is a type of recurrent neural network cell that aims to implement a perfect delay. It was first published by Volker, Kajic and Eliasmith (NeurIPs 2019) and has been shown to beat LSTMs on psMNIST dataset.\n",
    "\n",
    "<img src=\"https://i.imgur.com/IJGUVg6.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMUCell(nengo.Network):\n",
    "    \"\"\" Legendre Memory Unit \"\"\"\n",
    "    \n",
    "    def __init__(self, units, order, theta, input_d, **kwargs):\n",
    "        \"\"\" Constructor for LMU\n",
    "        \n",
    "        :param units:\n",
    "        :param order: The order of Lengendre Polynomials to use.\n",
    "        :param theta: Delay amount defining the sliding window from [t-theta, t]. \n",
    "                Can also be interpreted as length of time window.\n",
    "        :param input_d: Dimension of input signal X\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # Compute the analytically derived weight matrices used in LMU\n",
    "        # These are determined statistically based on the theta/order parameters.\n",
    "        Q = np.arange(order, dtype=np.float64)\n",
    "        R = (2 * Q + 1)[:, None] / theta\n",
    "        j, i = np.mesgrid(Q, Q)\n",
    "        \n",
    "        A = np.where(i < j, -1, (-1, 0) ** (i - j + 1) * R)\n",
    "        B = (-1.0) ** Q[:, None] * R\n",
    "        C = np.ones((1, order))\n",
    "        D = np.zeros((1,))\n",
    "        \n",
    "        A, B, _, _, _ = cont2discrete((A, B, C, D), dt=1.0, method=\"zoh\")\n",
    "        \n",
    "        with self:\n",
    "            nengo_dl.configure_settings(trainable=None)\n",
    "            \n",
    "            # Create objects corresponding to x/u/m/h variables of LMU cell\n",
    "            # There is a bit of notational change compared to X and U in NEF\n",
    "            # self.u is the input as seen by the dynamical system, self.m is the state from previous time,\n",
    "            # self.x is our actual data input.\n",
    "            self.x = nengo.Node(size_in=input_d)\n",
    "            self.u = nengo.Node(size_in=1)\n",
    "            self.m = nengo.Node(size_in=order)\n",
    "            self.h = nengo_dl.TensorNode(tf.nn.tanh, shape_in(units,), pass_time=False)\n",
    "            \n",
    "            # Compute u_t in the LMU cell. We have removed e_h and e_m as they are not needed in\n",
    "            # the psMNIST task. e_x is trainable, but initialized to np.ones instead of nengo_dl.dists.Glorot()\n",
    "            nengo.Connection(\n",
    "                self.x, self.u, transform=np.ones((1, input_d), synapse=None)\n",
    "            )\n",
    "            \n",
    "            # Compute m_t\n",
    "            # In this implementation we'll make A and B non-trainable, but they\n",
    "            # can also be optimized in the same way as other parameters. Note\n",
    "            # that setting synapse=0 (versus synapse=None) adds a one-timestep\n",
    "            # delay, so we can think of any connections with synapse=0 as representing\n",
    "            # value_{t-1}\n",
    "            conn_A = nengo.Connection(self.m, self.m, transform=A, synapse=0)\n",
    "            self.config[conn_A].trainable = False\n",
    "            conn_B = nengo.Connection(self.u, self.m, transform=B, synapse=None)\n",
    "            self.config[conn_B].trainable = False\n",
    "            \n",
    "            # Compute h_t\n",
    "            nengo.Connection(\n",
    "                # This is the W_x connection\n",
    "                self.x, self.h, transform=nengo_dl.dists.Glorot(), synapse=None\n",
    "            )\n",
    "            nengo.Connection(\n",
    "                # This is the W_h connection\n",
    "                self.h, self.h, transform=nengo_dl.dists.Glorot(), synapse=0\n",
    "            )\n",
    "            nengo.Connection(\n",
    "                # This is the W_m connection\n",
    "                self.m, self.h, transform=nengo_dl.dists.Glorot(), synapse=None\n",
    "            )\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, conn_A and conn_B "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c04d22d403ce73f48d72f35bf6f78bd964b4ebd2f32cc02a933a2ee1051d0284"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
